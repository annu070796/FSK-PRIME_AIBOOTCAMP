{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L982FdumDCVn"
      },
      "source": [
        "# Task 2: Data Preprocessing for Machine Learning – AI Bootcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EEWt7WNF5kP"
      },
      "source": [
        "Download Titanic Dataset here: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
        "\n",
        "#### About this file\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9AwRFXDO6n"
      },
      "source": [
        "## Section 1: Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2LLFb4DSrf"
      },
      "source": [
        "### **Task 1**: Load and Inspect a Dataset\n",
        "\n",
        "*Instruction*: Load the `titanic.csv` dataset and display the first 5 rows. Show basic info and describe statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6YtbgenDSWH",
        "outputId": "fb3d9253-40c4-473f-fff9-edf70e996fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 887 entries, 0 to 886\n",
            "Data columns (total 8 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Survived                 887 non-null    int64  \n",
            " 1   Pclass                   887 non-null    int64  \n",
            " 2   Name                     887 non-null    object \n",
            " 3   Sex                      887 non-null    object \n",
            " 4   Age                      887 non-null    float64\n",
            " 5   Siblings/Spouses Aboard  887 non-null    int64  \n",
            " 6   Parents/Children Aboard  887 non-null    int64  \n",
            " 7   Fare                     887 non-null    float64\n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 55.6+ KB\n",
            "None\n",
            "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
            "count  887.000000  887.000000  887.000000               887.000000   \n",
            "mean     0.385569    2.305524   29.471443                 0.525366   \n",
            "std      0.487004    0.836662   14.121908                 1.104669   \n",
            "min      0.000000    1.000000    0.420000                 0.000000   \n",
            "25%      0.000000    2.000000   20.250000                 0.000000   \n",
            "50%      0.000000    3.000000   28.000000                 0.000000   \n",
            "75%      1.000000    3.000000   38.000000                 1.000000   \n",
            "max      1.000000    3.000000   80.000000                 8.000000   \n",
            "\n",
            "       Parents/Children Aboard       Fare  \n",
            "count               887.000000  887.00000  \n",
            "mean                  0.383315   32.30542  \n",
            "std                   0.807466   49.78204  \n",
            "min                   0.000000    0.00000  \n",
            "25%                   0.000000    7.92500  \n",
            "50%                   0.000000   14.45420  \n",
            "75%                   0.000000   31.13750  \n",
            "max                   6.000000  512.32920  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CKwCBtDzRL"
      },
      "source": [
        "## Section 2: Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh1W_9m5DuzF"
      },
      "source": [
        "### **Task 2**: Identify and Handle Missing Data\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "\n",
        "\n",
        "*   Display the number of missing values per column.\n",
        "*   Fill missing `Age` values with the median.\n",
        "*   Drop the second row in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49610d9-4d4b-4da7-9536-49b30e499797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Name    0\n",
            "Age     2\n",
            "City    1\n",
            "dtype: int64\n",
            "Updated DataFrame:\n",
            "      Name   Age      City\n",
            "0    Alice  24.0  New York\n",
            "2  Charlie  22.0      None\n",
            "3    David  28.0   Chicago\n",
            "4      Eve  24.0   Houston\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e88250be09fb>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(median_age, inplace=True)  # Fill missing values\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with some missing values\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [24, None, 22, 28, None],\n",
        "    'City': ['New York', 'Los Angeles', None, 'Chicago', 'Houston']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 3: Display the number of missing values per column\n",
        "missing_values = df.isna().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Step 4: Fill missing Age values with the median\n",
        "median_age = df['Age'].median()  # Calculate median age\n",
        "df['Age'].fillna(median_age, inplace=True)  # Fill missing values\n",
        "\n",
        "# Step 5: Drop the second row of the dataset\n",
        "df.drop(index=1, inplace=True)  # Drop the second row\n",
        "\n",
        "# Step 6: Display the updated DataFrame\n",
        "print(\"Updated DataFrame:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVV1BgZvEE3a"
      },
      "source": [
        "## Section 3: Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUK7Z7LEIr4"
      },
      "source": [
        "### **Task 3**: Convert Categorical to Numeric\n",
        "\n",
        "*Instruction*: Convert `Sex` and `Pclass` columns to numeric using:\n",
        "\n",
        "\n",
        "*   Label Encoding for `Sex`\n",
        "*   One-Hot Encoding for `Pclass`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed38d738-b1af-4f44-d8c8-662ab301d8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed DataFrame:\n",
            "      Name  Sex  Pclass_2  Pclass_3\n",
            "0    Alice    0     False     False\n",
            "1      Bob    1     False      True\n",
            "2  Charlie    0      True     False\n",
            "3    David    1      True     False\n",
            "4      Eve    0     False     False\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample DataFrame containing Sex and Pclass columns\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Sex': ['female', 'male', 'female', 'male', 'female'],\n",
        "    'Pclass': ['1', '3', '2', '2', '1']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 3: Label Encode the Sex column\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])  # Convert 'female' to 0 and 'male' to 1\n",
        "\n",
        "# Step 4: One-Hot Encode the Pclass column\n",
        "df = pd.get_dummies(df, columns=['Pclass'], prefix='Pclass', drop_first=True)  # Drop first to avoid multicollinearity\n",
        "\n",
        "# Display the transformed DataFrame\n",
        "print(\"Transformed DataFrame:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNO0DPi3EpgF"
      },
      "source": [
        "## Section 4: Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74DNGaJEtdj"
      },
      "source": [
        "### **Task 4**: Scale Numerical Features\n",
        "\n",
        "*Instruction*: Use StandardScaler to scale the Age and Fare columns.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22ad093-86e1-4d2f-ce45-31454705fdaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed DataFrame:\n",
            "      Name       Age      Fare\n",
            "0    Alice -0.830019 -0.293610\n",
            "1      Bob  1.572667  1.321245\n",
            "2  Charlie -1.266871 -1.614856\n",
            "3    David  0.043685 -0.146805\n",
            "4      Eve  0.480537  0.734025\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [24, 35, 22, 28, 30],\n",
        "    'Fare': [72.5, 100.0, 50.0, 75.0, 90.0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the Age and Fare columns\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "# Display the transformed DataFrame\n",
        "print(\"Transformed DataFrame:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxPFagsE9mS"
      },
      "source": [
        "## Section 5: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwIOzHXFD1a"
      },
      "source": [
        "### **Task 5**: Build Preprocessing Pipeline\n",
        "\n",
        "*Instruction*: Using `ColumnTransformer` and `Pipeline` from `sklearn`, build a pipeline that:\n",
        "\n",
        "\n",
        "\n",
        "*   Imputes missing values\n",
        "*   Scales numeric data\n",
        "*   Encodes categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0feec088-1ac3-4073-956a-5c9c5175c657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed Data:\n",
            "[[-1.48196327 -0.33120483  0.          0.          0.          0.        ]\n",
            " [ 1.62310263  1.28801879  1.          0.          0.          1.        ]\n",
            " [ 0.         -1.65602416  0.          0.          1.          0.        ]\n",
            " [-0.3528484   0.          0.          1.          1.          0.        ]\n",
            " [ 0.21170904  0.6992102   0.          0.          0.          0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Age': [24, 35, None, 28, 30],\n",
        "    'Fare': [72.5, 100.0, 50.0, None, 90.0],\n",
        "    'Sex': ['female', 'male', 'female', None, 'female'],\n",
        "    'Pclass': [1, 3, 2, 2, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the numeric and categorical columns\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "# Define the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='mean')),  # Impute mean for numeric features\n",
        "            ('scaler', StandardScaler())                  # Scale numeric features\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute most frequent for categorical features\n",
        "            ('onehot', OneHotEncoder(drop='first'))              # One-hot encode categorical features\n",
        "        ]), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor)  # Apply the column transformations\n",
        "])\n",
        "\n",
        "# Fit and transform the data\n",
        "transformed_data = pipeline.fit_transform(df)\n",
        "\n",
        "# Display the transformed data\n",
        "print(\"Transformed Data:\")\n",
        "print(transformed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OY1jI5IaIB"
      },
      "source": [
        "## Section 6: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBCcr3RIi-8"
      },
      "source": [
        "### **Task 6**: Create a New Feature\n",
        "\n",
        "*Instruction*: Create a new feature `FamilySize` = `Siblings/Spouses Aboard` + `Parents/Children Aboard` + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf89f7d4-f7cd-467d-914d-798b8999cd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed Data:\n",
            "[[-1.48196327 -0.33120483  0.          0.          0.          0.        ]\n",
            " [ 1.62310263  1.28801879  1.          0.          0.          1.        ]\n",
            " [ 0.         -1.65602416  0.          0.          1.          0.        ]\n",
            " [-0.3528484   0.          0.          1.          1.          0.        ]\n",
            " [ 0.21170904  0.6992102   0.          0.          0.          0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Age': [24, 35, None, 28, 30],\n",
        "    'Fare': [72.5, 100.0, 50.0, None, 90.0],\n",
        "    'Sex': ['female', 'male', 'female', None, 'female'],\n",
        "    'Pclass': [1, 3, 2, 2, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the numeric and categorical columns\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "# Define the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='mean')),  # Impute mean for numeric features\n",
        "            ('scaler', StandardScaler())                  # Scale numeric features\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute most frequent for categorical features\n",
        "            ('onehot', OneHotEncoder(drop='first'))              # One-hot encode categorical features\n",
        "        ]), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor)  # Apply the column transformations\n",
        "])\n",
        "\n",
        "# Fit and transform the data\n",
        "transformed_data = pipeline.fit_transform(df)\n",
        "\n",
        "# Display the transformed data\n",
        "print(\"Transformed Data:\")\n",
        "print(transformed_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}